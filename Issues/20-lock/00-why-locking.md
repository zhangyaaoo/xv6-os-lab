
# 为什么需要锁？

![microprocessor-trend-data](assets/35years-microprocessor-trend-data.png)

这张图有点复杂，X轴是时间，Y轴是单位，Y轴具体意义取决于特定的曲线。这张图中的核心点是，大概从2000年开始：
- CPU的时钟频率就没有再增加过了（绿线）。
- 这样的结果是，CPU的单线程性能达到了一个极限并且也没有再增加过（蓝线）。
- 但是另一方面，CPU中的晶体管数量在持续的增加 （深红色线）。
- 所以现在不能通过使用单核来让代码运行的更快，要想运行的更快，唯一的选择就是使用多个CPU核。所以从2000年开始，处理器上核的数量开始在增加（黑线）。

我们希望使用多核并行提高性能，但如xv6内核中，有很多全局共享的数据结构，多核访问时，就会有竞争。为了保证数据的一致性和功能的正确性，我们需要使用锁来协调数据的访问。

内核中很多数据结构，通常需要以原子的方式执行共享数据的更新，这可能涉及多条指令，它们要么会一起执行，要么一条也不会执行。我们需要锁序列化了代码的执行。如果两个处理器想要进入到同一个critical section中，只会有一个能成功进入，另一个处理器会在第一个处理器从critical section中退出之后再进入。

这里完全没有并行执行，于是这些共享数据的访问又变成了串行。

这里有几点很重要，首先，并没有强制说一定要使用锁，锁的使用完全是由程序员决定的。如果你想要一段代码具备原子性，那么其实是由程序员决定是否增加锁的acquire和release。其次，代码不会自动加锁，程序员自己要确定好是否将锁与数据结构关联，并在适当的位置增加锁的acquire和release。


# 什么时候需要锁？

很明显，锁限制了并发性，也限制了性能。那这带来了一个问题，什么时候才必须要加锁呢？

我这里会给你们一个非常保守同时也是非常简单的规则：
如果两个进程访问了一个共享的数据结构，并且其中一个进程会更新共享的数据结构，
那么就需要对于这个共享的数据结构加锁。

除了共享的数据，在一些其他场合也需要锁。
例如对于printf，如果我们将一个字符串传递给它，XV6会尝试原子性的将整个字符串输出，而不是与其他进程的printf交织输出。
尽管这里没有共享的数据结构，但在这里锁仍然很有用处，因为我们想要printf的输出也是序列化的。

假设我们有一个对于rename的调用，这个调用会将文件从一个目录移到另一个目录，我们现在将文件d1/x移到文件d2/y。
如果只对数据结构自动加锁。现在我们有两个目录对象，一个是d1，另一个是d2，那么我们会先对d1加锁，删除x，之后再释放对于d1的锁；之后我们会对d2加锁，增加y，之后再释放d2的锁。
在这个例子中，我们会有错误的结果，那么为什么这是一个有问题的场景呢？为什么这个场景不能正常工作？
在我们完成了第一步，也就是删除了d1下的x文件，但是还没有执行第二步，也就是创建d2下的y文件时。其他的进程会看到什么样的结果？是的，其他的进程会看到文件完全不存在。这明显是个错误的结果，因为文件还存在只是被重命名了，文件在任何一个时间点都是应该存在的。但是如果我们按照上面的方式实现锁的话，那么在某个时间点，文件看起来就是不存在的。
所以这里正确的解决方法是，我们在重命名的一开始就对d1和d2加锁，之后删除x再添加y，最后再释放对于d1和d2的锁。
这个场景下，一系列的操作需要一起执行，不可分割，这个时候，锁应该与操作而不是数据关联，简单的对数据加锁不能很好的工作。或者说，d1和d2在这个场景下，应该看作一个整体数据对待。

总的来说，通常锁有三种作用，理解它们可以帮助你更好的理解锁。
- 锁可以避免丢失更新。多个writer同时更新一个共享数据时，避免出现写覆盖(race condition)，出现更新丢失。
- 锁可以打包多个操作，使它们具有原子性。我们之前介绍了加锁解锁之间的区域是critical section，在critical section的所有操作会都会作为一个原子操作执行。
- 锁可以维护共享数据结构的不变性。共享数据结构如果不被任何进程修改的话是会保持不变的。如果某个进程acquire了锁并且做了一些更新操作，共享数据的不变性暂时会被破坏，但是在release锁之后，数据的不变性又恢复了。



# 锁带来的挑战

先看两个死锁的场景：
- 场景一：首先acquire一个锁，然后进入到critical section；在critical section中，再acquire同一个锁；第二个acquire必须要等到第一个acquire状态被release了才能继续执行，但是不继续执行的话又走不到第一个release，所以程序就一直卡在这了。如：单核系统中，线程acquire一个锁后，发生了中断，中断中又去acquire同一把锁。
- 场景二：线程A先后获取锁x和锁y，线程B先后获取锁y和锁x，就有可能发生：线程A获取锁x后，等待获取锁y，线程B获取锁y后，等待获取锁x。发生死锁。

对于场景二，当有多个锁的时候，需要对锁进行排序，所有的操作都必须以相同的顺序获取锁。

不过在设计一个操作系统的时候，定义一个全局的锁的顺序会有些问题。如果一个模块m1中方法g调用了另一个模块m2中的方法f，那么m1中的方法g需要知道m2的方法f使用了哪些锁。因为如果m2使用了一些锁，那么m1的方法g必须集合f和g中的锁，并形成一个全局的锁的排序。这意味着在m2中的锁必须对m1可见，这样m1才能以恰当的方法调用m2。

但是这样又违背了代码抽象的原则。在完美的情况下，代码抽象要求m1完全不知道m2是如何实现的。但是不幸的是，具体实现中，m2内部的锁需要泄露给m1，这样m1才能完成全局锁排序。所以当你设计一些更大的系统时，锁使得代码的模块化更加的复杂了。

那我们是不是可以用一把大锁，锁上所有的共享数据呢？但这又带来对性能的影响。

基本上来说，如果你想获得更高的性能，你需要拆分数据结构和锁。如果你只有一个big kernel lock，那么操作系统只能被一个CPU运行。如果你想要性能随着CPU的数量增加而增加，你需要将数据结构和锁进行拆分。

通常来说，开发的流程是：
- 先以coarse-grained lock（注，也就是大锁）开始。
- 再对程序进行测试，来看一下程序是否能使用多核。
- 如果可以的话，那么工作就结束了，你对于锁的设计足够好了；如果不可以的话，那意味着锁存在竞争，多个进程会尝试获取同一个锁，因此它们将会序列化的执行，性能也上不去，之后你就需要重构程序。

在这个流程中，测试的过程比较重要。有可能模块使用了coarse-grained lock，但是它并没有经常被并行的调用，那么其实就没有必要重构程序，因为重构程序设计到大量的工作，并且也会使得代码变得复杂。所以如果不是必要的话，还是不要进行重构。


总的来说，锁带来了三个挑战：1.死锁的问题；2.破坏程序的模块化；3.对性能的影响。